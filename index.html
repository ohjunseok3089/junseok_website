<!DOCTYPE HTML>
<html lang="en">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<title>Junseok Oh</title>

	<meta name="author" content="Junseok Oh">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
	<link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
	<table
		style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>
			<tr style="padding:0px">
				<td style="padding:0px">
					<table
						style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr style="padding:0px">
								<td style="padding:2.5%;width:63%;vertical-align:middle">
									<p class="name" style="text-align: center;">
										Junseok (June) Oh
									</p>
									<p>
										Hi! I'm Junseok, pursuing an MSE in Data Science at the <a
											href="https://www.upenn.edu/" target="_blank"
											rel="noopener noreferrer">University of Pennsylvania</a>. My goal is to
										develop human-centric social robots that support caregivers and patients through
										multimodal interaction.
									</p>
									<p>
										I study multimodal social attention: how an agent can infer who needs attention,
										what matters in the moment, and when assistance is appropriate from cues like
										gaze, head orientation, language, and turn-taking.
										At the <a href="https://www.media.mit.edu/groups/personal-robots/overview/"
											target="_blank" rel="noopener noreferrer">MIT Media Lab Personal Robots
											Group</a> (mentored by <a href="https://dongwonl.com" target="_blank"
											rel="noopener noreferrer">Dong Won Lee</a> and <a
											href="https://www.media.mit.edu/people/haewon/overview/" target="_blank"
											rel="noopener noreferrer">Dr. Hae Won Park</a>), I work on multimodal
										egocentric head-gaze prediction. Previously, I worked on health-focused projects
										spanning smartphone-based biosensing and single-cell analysis.
										I also have industry experience at Hewlett Packard Enterprise (HPE), where I
										worked full-time as a Cloud AI Software Engineer and previously interned in Data
										Science.
									</p>
									<p>
										I earned my B.S. in Computer Science from <a href="https://www.cs.purdue.edu/"
											target="_blank" rel="noopener noreferrer">Purdue University</a>, with a
										minor in Mathematics.
									</p>
									<p style="text-align:center">
										<a href="mailto:junseok.oh.1020@gmail.com" target="_blank"
											rel="noopener noreferrer">Email</a> &nbsp;/&nbsp;
										<a href="data/Junseok_Oh_CV.pdf" target="_blank"
											rel="noopener noreferrer">CV</a> &nbsp;/&nbsp;
										<a href="https://scholar.google.com/citations?user=zBsSSX0AAAAJ&hl=en"
											target="_blank" rel="noopener noreferrer">Scholar</a> &nbsp;/&nbsp;
										<a href="https://github.com/ohjunseok3089" target="_blank"
											rel="noopener noreferrer">GitHub</a>
									</p>
								</td>
								<td style="padding:2.5%;width:37%;max-width:37%">
									<a href="images/junseok_photo.jpeg" target="_blank" rel="noopener noreferrer"><img
											style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;"
											alt="profile photo" src="images/junseok_photo.jpeg"
											class="hoverZoomLink"></a>
								</td>
							</tr>
						</tbody>
					</table>

					<table
						style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:100%;vertical-align:middle">
									<h2>Research</h2>
									<!-- Selected publications -->
								</td>
							</tr>
						</tbody>
					</table>
					<table
						style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<a href="projects/prg/index.html" target="_blank" rel="noopener noreferrer">
										<img src="images/ego-gaze.png" alt="Egocentric head gaze prediction overview"
											width="160" height="160"
											style="width:160px; height:160px; object-fit:contain; border-radius: 10px;">
									</a>
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<span class="papertitle">Social Egocentric Head Gaze Prediction with Vision
										Embeddings Fused with Speaker Audio Language</span>
									<br>
									<strong>Junseok Oh*</strong>, <a href="https://dongwonl.com" target="_blank"
										rel="noopener noreferrer">Dong Won Lee</a>*, <a
										href="https://www.cs.cmu.edu/~morency/" target="_blank"
										rel="noopener noreferrer">Louis-Philippe Morency</a>, <a
										href="https://www.media.mit.edu/people/cynthiab/overview/" target="_blank"
										rel="noopener noreferrer">Cynthia Breazeal</a>, <a
										href="https://www.media.mit.edu/people/haewon/overview/" target="_blank"
										rel="noopener noreferrer">Hae Won Park</a>
									<br>
									<em>In Preparation</em>
									<br>
									<a href="projects/prg/index.html" target="_blank" rel="noopener noreferrer">project
										page</a>
									<p>
										We study social egocentric head-gaze prediction by fusing vision embeddings with
										speaker-aware audio and language cues.
									</p>
								</td>
							</tr>
							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<a href="https://doi.org/10.1109/JSEN.2025.3560823" target="_blank"
										rel="noopener noreferrer">
										<img src="images/sensors2025.png"
											alt="Smartphone-integrated Salmonella detection platform" width="160"
											height="160"
											style="width:160px; height:160px; object-fit:contain; border-radius: 10px;">
									</a>
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<a href="https://doi.org/10.1109/JSEN.2025.3560823" target="_blank"
										rel="noopener noreferrer">
										<span class="papertitle">Smartphone-Integrated Optomechanical Dual-Mode
											Instrument for Salmonella Typhimurium Detection</span>
									</a>
									<br>
									<a href="https://scholar.google.com/citations?user=ATvZ74sAAAAJ&hl=en"
										target="_blank" rel="noopener noreferrer">Hyun Jung Min</a>, <a
										href="https://ag.purdue.edu/department/foodsci/graduate-student-profiles/hansel-mina.html"
										target="_blank" rel="noopener noreferrer">Hansel A. Mina</a>, <strong>Junseok
										Oh</strong>, <a href="https://ag.purdue.edu/directory/adeering" target="_blank"
										rel="noopener noreferrer">Amanda J. Deering</a>, <a
										href="https://vet.purdue.edu/directory/person.php?id=166" target="_blank"
										rel="noopener noreferrer">J. Paul Robinson</a>, <a
										href="https://web.ics.purdue.edu/~brajwa/" target="_blank"
										rel="noopener noreferrer">Bartek Rajwa</a>, <a
										href="https://engineering.purdue.edu/ME/People/ptProfile?resource_id=69328"
										target="_blank" rel="noopener noreferrer">Euiwon Bae</a>
									<br>
									<em>IEEE Sensors Journal</em>, 2025
									<br>
									<a href="https://doi.org/10.1109/JSEN.2025.3560823" target="_blank"
										rel="noopener noreferrer">paper</a>
									<p>
										We develop a smartphone-integrated, optomechanical dual-mode biosensing
										instrument that combines vision-based readout with frequency-shift measurements
										to enable low-cost, rapid detection of <em>Salmonella Typhimurium</em> for
										practical food-safety monitoring.
									</p>
								</td>
							</tr>
						</tbody>
					</table>

					<table
						style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:100%;vertical-align:middle">
									<h2>Research Projects</h2>
									<!-- Selected research experiences -->
								</td>
							</tr>
						</tbody>
					</table>
					<table
						style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<img src="images/stanford-kbiox.png"
										alt="Stanford Cardiovascular Institute scRNA-seq" width="160" height="160"
										style="width:160px; height:160px; object-fit:cover; border-radius: 10px;">
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<p>
										<a href="https://med.stanford.edu/cvi.html" target="_blank"
											rel="noopener noreferrer"><span class="papertitle">K-BioX - Stanford
												Cardiovascular Institute</span></a>
										<br>
										Jan 2022 &ndash; Aug 2022 and Jan 2024 &ndash; May 2024
										<br>
										Advisors: <a href="https://med.stanford.edu/profiles/siyeon-rhee"
											target="_blank" rel="noopener noreferrer">Dr. Siyeon Rhee</a> and <a
											href="https://med.stanford.edu/wulab.html" target="_blank"
											rel="noopener noreferrer">Prof. Joseph C. Wu</a>
									</p>
									<p>
										Built an automated scRNA-seq pipeline over public GEO datasets to compare adult
										vs. P12 developmental stages, then used GSEA, cell-to-cell interaction
										profiling, and PCA/UMAP to surface adipogenesis/angiogenesis signals across
										epicardial adipose tissue (EAT) datasets.
									</p>
								</td>
							</tr>

							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<img src="images/wittgen.png" alt="Wittgen Biotechnology, UC Berkeley SkyDeck"
										width="160" height="160"
										style="width:160px; height:160px; object-fit:cover; border-radius: 10px;">
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<p>
										<a href="https://www.wittgenbio.com/" target="_blank"
											rel="noopener noreferrer"><span class="papertitle">Wittgen Biotechnology -
												UC Berkeley SkyDeck</span></a>
										<br>
										May 2022 &ndash; Aug 2022
										<br>
										Research Intern
									</p>
									<p>
										Worked on ML for high-resolution tumor classification and tailored drug
										recommendations by processing RNA-seq data from 40+ cancer patients,
										contributing to an AI platform for cancer heterogeneity profiling, and using
										Seurat for single-cell analysis and cell-type differentiation.
									</p>
								</td>
							</tr>
						</tbody>
					</table>

					<table
						style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:100%;vertical-align:middle">
									<h2>GitHub Projects</h2>
								</td>
							</tr>
						</tbody>
					</table>
					<table
						style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<div class="colored-box"
										style="background-color: #eef6ff; width:160px; height:160px; padding:0; display:flex; align-items:center; justify-content:center; text-align:center; border-radius: 10px;">
										Real-time<br>
										Object<br>
										Recognition
									</div>
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<a href="https://github.com/ohjunseok3089/real-time-ground-truth" target="_blank"
										rel="noopener noreferrer">
										<span class="papertitle">Real-time Object Recognition</span>
									</a>
									<p>
										A lightweight repository for real-time object recognition experiments and
										evaluation.
									</p>
								</td>
							</tr>

							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<div class="colored-box"
										style="background-color: #f4f4f4; width:160px; height:160px; padding:0; display:flex; align-items:center; justify-content:center; text-align:center; border-radius: 10px;">
										Egocentric<br>
										Dataset
									</div>
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<a href="https://github.com/ohjunseok3089/ego-dataset" target="_blank"
										rel="noopener noreferrer">
										<span class="papertitle">Egocentric Dataset</span>
									</a>
									<p>
										Data collection and preprocessing utilities for egocentric video datasets.
									</p>
								</td>
							</tr>

							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<div class="colored-box"
										style="background-color: #fff3e6; width:160px; height:160px; padding:0; display:flex; align-items:center; justify-content:center; text-align:center; border-radius: 10px;">
										Egocentric<br>
										Modeling
									</div>
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<a href="https://github.com/ohjunseok3089/co-tracker-PRG" target="_blank"
										rel="noopener noreferrer">
										<span class="papertitle">Egocentric Modeling</span>
									</a>
									<p>
										Modeling and experimentation code for egocentric perception tasks.
									</p>
								</td>
							</tr>
						</tbody>
					</table>

					<table
						style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:100%;vertical-align:middle">
									<h2>Teaching</h2>
								</td>
							</tr>
						</tbody>
					</table>
					<table
						style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:16px;width:20%;vertical-align:middle">
									<img src="images/purdue-cs.webp" alt="Purdue Computer Science" width="160"
										height="160"
										style="width:160px; height:160px; object-fit:cover; border-radius: 10px;">
								</td>
								<td style="padding:8px;width:80%;vertical-align:middle">
									<a href="https://catalog.purdue.edu/preview_course_nopop.php?catoid=8&coid=77777"
										target="_blank" rel="noopener noreferrer">
										<span class="papertitle">CS 25200 - Systems Programming</span>
									</a>
									<br>
									Undergraduate TA, Spring 2023
								</td>
							</tr>
						</tbody>
					</table>
					<table
						style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
						<tbody>
							<tr>
								<td style="padding:0px">
									<br>
									<p style="text-align:right;font-size:small;">
										Template based on <a href="https://github.com/jonbarron/jonbarron_website"
											target="_blank" rel="noopener noreferrer">Jon Barron</a>'s website; see <a
											href="https://github.com/leonidk/new_website" target="_blank"
											rel="noopener noreferrer">Leonid Keselman</a>'s Jekyll fork.
									</p>
								</td>
							</tr>
						</tbody>
					</table>
				</td>
			</tr>
	</table>
</body>

</html>